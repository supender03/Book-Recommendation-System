{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dacbf2-5214-4f57-8dca-a76801621fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a239acb-1f9e-4b67-b044-8340bc34619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load a sample recipe dataset\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Preview dataset\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674a916-e437-4535-a989-dc105868ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87077135-7b79-4991-9d2a-31486dcb3b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517fd553-e411-43dc-9d22-53bdba0169b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.duplicated(['TranslatedInstructions'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b3b30d-2fed-4d68-9f05-5466c451aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['TranslatedInstructions'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f922816c-ab8b-4f92-92f9-0b20590e4688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenization: Converting words into integers\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['TranslatedInstructions'])\n",
    "\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Creating input sequences\n",
    "input_sequences = []\n",
    "for line in data['TranslatedInstructions']:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Padding sequences and creating predictors and label\n",
    "max_sequence_length = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "\n",
    "# Defining a generator function for batch processing\n",
    "def sequence_generator(input_sequences, labels, batch_size):\n",
    "    num_batches = len(input_sequences) // batch_size\n",
    "    while True:\n",
    "        for batch in range(num_batches):\n",
    "            start = batch * batch_size\n",
    "            end = (batch + 1) * batch_size\n",
    "            yield X[start:end, :], y[start:end, :]\n",
    "\n",
    "# Model definition\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100))\n",
    "model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words/2, activation='relu'))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model using fit_generator\n",
    "batch_size = 32\n",
    "num_epochs = 50  \n",
    "steps_per_epoch = len(input_sequences) // (batch_size)\n",
    "\n",
    "model.fit_generator(\n",
    "    sequence_generator(X, y, batch_size),\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Generating a recipe\n",
    "def generate_recipe(seed_text, next_words=10):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Example usage\n",
    "generated_recipe = generate_recipe(\"Blend onions\")\n",
    "print(generated_recipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706cbd6b-b51c-47c3-97d0-bb22c89bd0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
